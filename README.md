# Real-Time-Stock-Market-Data-Streaming-System

## Introduction
This project involves executing an end-to-end data engineering project focused on real-time stock market data using Kafka. The aim is to build a robust data pipeline capable of ingesting, processing, and analyzing streaming data from stock markets in real-time. By leveraging various technologies, including Python, Amazon Web Services (AWS) and Apache Kafka, this project demonstrates how to handle real-time data flows and derive actionable insights.

## Objectives:
### Data Ingestion: Capture real-time stock market data using Kafka.
### Data Processing: Utilize AWS services such as Glue and Athena to process and analyze the data.
### Data Storage: Store the processed data in AWS S3 for scalable and durable storage.
### Data Analysis: Use SQL queries in Athena to analyze the data and extract meaningful information.
### Real-Time Monitoring: Ensure the pipeline is monitored and maintained for performance and reliability.

## Key Features:
### Scalability: The use of AWS services ensures that the pipeline can scale according to the data load.
### Flexibility: Apache Kafka allows for easy integration with various data sources and sinks.
### Cost-Effectiveness: Utilizing AWS managed services helps in reducing the operational overhead and costs.
### Real-Time Processing: The architecture is designed to handle real-time data, providing up-to-date insights.

## My Learning Outcomes:
1. Learnt how to configure **Apache Kafka** for capturing real-time stock market data streams.
2. Understood **Kafka producers and consumers** and how to set them up for efficient data ingestion.
3. Explored how to use **AWS S3** for scalable and durable data storage. Gain knowledge on best practices for organizing and managing large datasets in S3.
4. Mastered the setup and usage of **AWS Glue** for data cataloging. Performing **ETL** (Extract, Transform, Load) processes using Glue to clean and preprocess data.
5. Learnt how to use AWS Athena to perform **SQL queries** on data stored in S3. Understood the benefits of serverless querying and how to optimize query performance.
6. Developed skills in **real-time data processing and monitoring**.
7. Gained hands-on experience in designing and **implementing a complete data pipeline**.

## Technologies Used
### Programming Language: Python
### Amazon Web Services (AWS):
#### S3 (Simple Storage Service)
#### EC2
#### Athena
#### Glue Crawler
#### Glue Catalog
#### Apache Kafka
